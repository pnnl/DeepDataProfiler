<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Overview &mdash; Deep Data Profiler 2.0.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="classes" href="../classes/modules.html" />
    <link rel="prev" title="Deep Data Profiler (DDP)" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Deep Data Profiler
            <img src="../_static/Profilingicon.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#related-work">Related Work</a></li>
<li class="toctree-l2"><a class="reference internal" href="#profiling-methods">Profiling Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#svd-profiles">SVD Profiles</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#profile-graphs">Profile Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#topological-data-analysis">Topological Data Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#metric-space">Metric Space</a></li>
<li class="toctree-l3"><a class="reference internal" href="#persistent-homology">Persistent Homology</a></li>
<li class="toctree-l3"><a class="reference internal" href="#persistence-images">Persistence Images</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tda-visualization-tool">TDA Visualization Tool</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../classes/modules.html">Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/modules.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing Deep Data Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tableofcontents.html">Index</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Deep Data Profiler</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Overview</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/overview/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <a class="reference internal image-reference" href="../_images/eaglegraph.png"><img alt="../_images/eaglegraph.png" class="align-right" src="../_images/eaglegraph.png" style="width: 500px;" /></a>
<section id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline"></a></h2>
<p>Deep neural networks (DNN) provide powerful and succesful classification tools.
Unfortunately they are often very complex and can involve millions of trained parameters.
This complexity makes it difficult to connect the input domain to the decisions used to classify its elements.
<em>Does the network really see a bird or does it just see blue sky and infer there is a bird?</em>
The <a class="reference external" href="https://github.com/pnnl/DeepDataProfiler">DeepDataProfiler</a> (DDP) challenge is to link hidden representations of existing trained neural networks to human recognizable input features
and to identify training invariant structures and metrics for determining trustworthiness of the network.</p>
<p>DDP is both a methodology and software package.
The methodology has two steps.</p>
<ol class="arabic simple">
<li><p><strong>Profiling:</strong> Generate representations of data using the graph (or subnetwork) of neurons and synapses they most activate in a trained DNN.</p></li>
<li><p><strong>Analysis:</strong> Apply Graph Theory and Topological Data Analysis (TDA) to identify structural features of the graphs that may be used to explain and interpret the decision process of the network.</p></li>
</ol>
<p>The DDP software is the implemention of this methodology in Python using the PyTorch library.
Our first release in May 2020 profiled VGG-like Sequential CNN architectures.
The current release extends to ResNet architectures.
At present only models built using PyTorch can be profiled.
Our TDA work is implemented in the homology module in the algorithms directory and depends on ripser.</p>
</section>
<section id="related-work">
<h2>Related Work<a class="headerlink" href="#related-work" title="Permalink to this headline"></a></h2>
<p>Providing human interpretable explanations for the decisions made by deep neural networks is a high
priority for machine learning practioners. One popular approach is to link input data to the most influential
<strong>neurons</strong> and <strong>synapses</strong> used for their classification.
Our research in this area was inspired by <a class="reference external" href="https://arxiv.org/abs/1904.08089">Yuxian Qiu, Jingwen Leng, Cong Guo, Quan Chen, Chao Li,Minyi Guo, and Yuhao Zhu.
Adversarial Defense Through Net-work Profiling Based Path Extraction.
In2019 IEEE/CVF Con-ference on Computer Vision and Pattern Recognition (CVPR),
pages 4772–4781, Long Beach, CA, USA, June 2019. IEEE</a>
They create <em>graph-like</em> objects called <strong>effective paths</strong> to explore the internal organization of deep neural networks.</p>
<p>Deep neural networks lend themselves naturally to decomposition into graphs as they are already <em>graph like</em>
in their neural connections. Such decompositions have been explored in particular in image classification networks.
<a class="reference external" href="https://fredhohman.com/summit/">Summit</a> creates an <strong>attribution graph</strong> of the convolutional layers
to visualize neuron activations and linking, see
<a class="reference external" href="https://arxiv.org/abs/1904.02323">F. Hohman, et al., “Summit: Scaling Deep Learning
Interpretability by Visualizing Activation and Attribution Summarizations,”  arXiv:1708.01785 [cs], Nov. 2017</a></p>
<p>Q. Zhang et al. create <strong>explanatory graphs</strong> to expose the knowledge hierarchy hidden inside a pre-trained
CNN, see: <a class="reference external" href="http://arxiv.org/abs/1708.01785">Q. Zhang, R. Cao, F. Shi, Y. N. Wu, and S.-C. Zhu, “Interpreting CNN Knowledge via an Explanatory Graph,”
arXiv:1708.01785 [cs], Nov. 2017.</a></p>
<p>N. Cammarata, et al. describe <strong>circuits</strong> of neurons from the convolutional layers of a network,
which connect to represent features
of an image used for classification, see <a class="reference external" href="https://distill.pub/2020/circuits/">N. Cammarata, S. Carter, G. Goh, C. Olah, M. Petrov, and L. Schubert,
“Thread: Circuits,” Distill, vol. 5, no. 3, p. e24, Mar. 2020, doi: 10.23915/distill.00024.</a></p>
<img alt="../_images/Background.png" class="align-right" src="../_images/Background.png" />
<p>The <a class="reference external" href="https://github.com/pnnl/DeepDataProfiler">DeepDataProfiler</a>  library builds on the ideas above to provide tools for the analysis of the internal decision
structure of a deep neural network.
Given a trained model, DDP generates <strong>profile graphs</strong> for inputs. These graphs are similar to the effective paths in <a class="reference external" href="https://arxiv.org/abs/1904.08089">Qiu’s</a> paper
but with weighting and attribution similar to the graphs generated in <a class="reference external" href="https://fredhohman.com/summit/">Summit</a> .
At present the library has a
working pipeline to generate profiles using VGG and ResNet architectures implemented in <a class="reference external" href="https://pytorch.org/">PyTorch</a>.</p>
<img alt="../_images/pipelineimg.png" class="align-right" src="../_images/pipelineimg.png" />
<p>We apply Graph Theory and Topological Data Analysis to the profile graphs to explore their structure.
The Algorithms directory contains modules
for exploring the persistent homology of point clouds
generated from profile graphs and for
exploring the empirical spectral decomposition
of the model’s linear operators.</p>
<p>Jupyter notebooks for the library with illustrative examples are available in the tutorials directory.</p>
</section>
<hr class="docutils" />
<section id="profiling-methods">
<h2>Profiling Methods<a class="headerlink" href="#profiling-methods" title="Permalink to this headline"></a></h2>
<p>The goal of DeepDataProfiler is to analyze activations to identify neurons that are key
to the classification of an input, but there are many ways to define a neuron and
measure its importance. DDP supports analysis on four different types of neurons:
Element neurons, Channel neurons, Spatial neurons, and SVD neurons.</p>
<p>Convolutional layers of a CNN produce 3-dimensional <em>tensors</em> of activations, and we can
slice that tensor into neuron units in a few different ways.</p>
<img alt="../_images/tensor_slices.png" class="align-right" src="../_images/tensor_slices.png" />
<p>In a <span class="math notranslate nohighlight">\(c\times m\times m\)</span> activation tensor, there are:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(c\)</span> <strong>channels</strong>, which are the <span class="math notranslate nohighlight">\(m\times m\)</span> matrices, or planes of
the tensor,</p></li>
<li><p><span class="math notranslate nohighlight">\(m^2\)</span> <strong>spatials</strong>, which are the <span class="math notranslate nohighlight">\(c\)</span>-vectors through all channels of the
tensor at a fixed spatial (row and column) position,</p></li>
<li><p>and <span class="math notranslate nohighlight">\(cm^2\)</span> <strong>elements</strong>, which are the individual cells of the tensor at a fixed channel
and spatial position.</p></li>
</ul>
</div></blockquote>
<p>See the documentation for <code class="code docutils literal notranslate"><span class="pre">ddp.ElementProfiler</span></code>, <code class="code docutils literal notranslate"><span class="pre">ddp.ChannelProfiler</span></code>, and
<code class="code docutils literal notranslate"><span class="pre">ddp.SpatialProfiler</span></code> for more information on how each of these profiling methods, and
visit Tutorial 1 for an interactive overview.</p>
<section id="svd-profiles">
<h3>SVD Profiles<a class="headerlink" href="#svd-profiles" title="Permalink to this headline"></a></h3>
<p>Each convolutional layer has a learned weight tensor <span class="math notranslate nohighlight">\(\text W\)</span> with dimensions <span class="math notranslate nohighlight">\(d\times c\times
k\times k\)</span>. We can unfold that tensor into a <span class="math notranslate nohighlight">\(d\times ck^2\)</span> matrix <span class="math notranslate nohighlight">\(\overline W\)</span>, and take its
singular value decomposition (SVD) to find a basis of singular directions.</p>
<img alt="../_images/w_unfold.png" class="align-right" src="../_images/w_unfold.png" />
<p>These SVD directions expose the core dynamics of the linear transformation that occurs when an
input tensor is convolved with the weight tensor for this layer. We can identify
the most important singular directions, or SVD neurons, by projecting the raw
activations onto the SVD basis and measuring their <em>signals</em>, or strength in the
direction of each singular direction. See the documentation for <code class="code docutils literal notranslate"><span class="pre">ddp.SVDProfiler</span></code>
for more information.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 53%" />
<col style="width: 47%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Standard Activation Basis</p></th>
<th class="head"><p>SVD Basis</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><div class="line-block">
<div class="line"><code class="code docutils literal notranslate"><span class="pre">ddp.ElementProfiler</span></code></div>
<div class="line"><code class="code docutils literal notranslate"><span class="pre">ddp.ChannelProfiler</span></code></div>
<div class="line"><code class="code docutils literal notranslate"><span class="pre">ddp.SpatialProfiler</span></code></div>
</div>
</td>
<td><div class="line-block">
<div class="line"><code class="code docutils literal notranslate"><span class="pre">ddp.SVDProfiler</span></code></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
</tbody>
</table>
<hr class="docutils" />
<p>Deep Data Profiler builds a profile of a model-data pairing by
identifying key neurons and the synapses that connect them. This data
naturally lends itself to representation as a directed bipartite graph,
allowing us to take advantage of the rich field of graph theoretical
analysis tools. Visit <a class="reference external" href="https://colab.research.google.com/github/pnnl/DeepDataProfiler/blob/master/tutorials/Tutorial%202%20-%20DDPAlgorithms.ipynb">Tutorial 2 - Topological Data
Analysis</a>
for an interactive walkthrough of some of the content on this page.</p>
</section>
</section>
<section id="profile-graphs">
<h2>Profile Graphs<a class="headerlink" href="#profile-graphs" title="Permalink to this headline"></a></h2>
<p>To construct a profile graph, we treat the influential neurons as
vertices and the influential synapses that connect them as edges. In
this graph, edge weights are defined as a function of the influence
weight assigned to the corresponding synapse. We have explored two such
functions, which we refer to as the original and inverted weighting
schemes. Under the original weighting scheme the weight of an edge is
equal to the influence weight of its corresponding synapse, so nodes
connected by synapses with greater influence weights are further apart
by shortest path distance. We define the inverted weighting scheme to
assign a weight of <span class="math notranslate nohighlight">\(w_i^{-1}\)</span> to edge <span class="math notranslate nohighlight">\(i\)</span>, where <span class="math notranslate nohighlight">\(w_i\)</span>
is the influence weight of the corresponding synapse <span class="math notranslate nohighlight">\(i\)</span>. Profile
graphs that use the inverted weighting scheme are appropriate when our
method of analyzing the graph places greater importance on points that
are close together.</p>
<img alt="Eagle Profile Graph" src="../_images/eaglegraph.png" />
</section>
<section id="topological-data-analysis">
<h2>Topological Data Analysis<a class="headerlink" href="#topological-data-analysis" title="Permalink to this headline"></a></h2>
<p>Topological Data Analysis (TDA) is a powerful tool for the analysis of
large metrizable spaces of data. We explore the use of TDA to analyze
the structure of profile graphs and uncover meaning behind the
interconnection of the synapses, independent of labels on nodes and
synapses. To accomplish this, we define a metric space on the vertices
of a profile graph, which we can then analyze using persistent homology.</p>
<img alt="Pipeline" src="../_images/pipelineimg.png" />
<section id="metric-space">
<h3>Metric Space<a class="headerlink" href="#metric-space" title="Permalink to this headline"></a></h3>
<p>The vertices of the profile graph can be represented in a metric space
by constructing the distance matrix using the shortest path distance.
Optionally, some kernel function can then be applied to the distances to
produce a desired effect on the metric space. One example that we have
explored is the Gaussian kernel, given by
<span class="math notranslate nohighlight">\(g(x) = 1 - e^{-x/2\sigma}\)</span>, where <span class="math notranslate nohighlight">\(\sigma\)</span> is the standard
deviation of the finite shortest path distances. The Gaussian kernel is
an increasing function that spreads out low distances and contracts high
distances. When the edge weights of a profile graph are defined
according to an inverted weighting scheme, the low distances correspond
to the most influential connections. In this case, spreading out the low
distances can reveal more nuanced structures that emerge at those
distance thresholds.</p>
</section>
<section id="persistent-homology">
<h3>Persistent Homology<a class="headerlink" href="#persistent-homology" title="Permalink to this headline"></a></h3>
<p>Persistent homology allows us to summarize the “shape” of profile graph
data based on the appearance of topological features at different
distance thresholds. We calculate the persistent homology of a metric
space, and then study its persistence diagram to identify topological
features of the corresponding profile graph. Persistence diagrams allow
us to visualize the persistence of features by plotting a point for each
topological feature, whose coordinates are <span class="math notranslate nohighlight">\((birth, death)\)</span>. The
<span class="math notranslate nohighlight">\(birth\)</span> of a feature, such as an open loop, represents the
distance threshold when the loop was formed, and the <span class="math notranslate nohighlight">\(death\)</span>
represents the distance threshold when the loop was closed or
triangulated. For a more in depth introduction to persistent homology,
<a class="reference external" href="https://learning-analytics.info/index.php/JLA/article/view/5196">A User’s Guide to Topological Data
Analysis</a>
by Elizabeth Munch gives an overview of modern TDA methods, including
persistent homology (Section 3).</p>
</section>
<section id="persistence-images">
<h3>Persistence Images<a class="headerlink" href="#persistence-images" title="Permalink to this headline"></a></h3>
<p>Persistence images are finite-dimensional vector representations of
persistence diagrams, proposed by Adams et. al. in <a class="reference external" href="https://www.jmlr.org/papers/volume18/16-337/16-337.pdf">Persistence Images:
A Stable Vector Representation of Persistent
Homology</a>. We
have used persistence images as part of our initial exploration of the
topological features of profile graphs, since they provide alternative
visualizations that can be compared by Euclidean distances (a metric
that is much more computationally efficient than the current standard
methods for comparing persistence diagrams).</p>
<img alt="Persistence Diagram vs. Persistence Image" src="../_images/PDtoPI.png" />
</section>
</section>
<section id="tda-visualization-tool">
<h2>TDA Visualization Tool<a class="headerlink" href="#tda-visualization-tool" title="Permalink to this headline"></a></h2>
<p>Our TDA visualization tool allows persistence diagrams and persistence
images to be viewed alongside the input image from which their
corresponding profile graph was generated by Deep Data Profiler. The
tool includes image and persistence data for 50 images from each class
of the ImageNet1k dataset, profiled using element-wise and channel-wise
neuron definitions, on both VGG16 and ResNet-18 architectures. All
persistence images were generated using the same scale and parameters,
so they can be visually compared between different input images and
classes. [link]</p>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="Deep Data Profiler (DDP)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../classes/modules.html" class="btn btn-neutral float-right" title="classes" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, 2022, Battelle Memorial Institute.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>