{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db6cc22",
   "metadata": {},
   "source": [
    "## Beginner Feature Visualization Tutorial\n",
    "\n",
    "This DeepDataProfiler module builds on the [Lucid](https://github.com/tensorflow/lucid) and [Lucent](https://github.com/greentfrapp/lucent) feature visualization libraries. We build on these approaches by projecting the activations of a hidden layer onto the basis of eigenvectors of the weights for that layer. See our upcoming paper for more information.\n",
    "\n",
    "\n",
    "First, preliminary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_data_profiler.optimization import dictionary_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a882d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=True)\n",
    "_ = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d3cb3",
   "metadata": {},
   "source": [
    "### The easiest function to use for feature visualization is `dictionary_optimization`.  This tutorial covers the use of this function.\n",
    "\n",
    "It reads a dictionary of either `{layer : [neurons...]}` or `{layer : [(neuron, weight), ...]}`\n",
    "and returns a single objective to optimize. It also accepts a `neuron_type` (namely, Euclidean or SVD, it defaults to SVD), and whether to consider a single receptive field or the entire channel/signal (`neuron=False` optimizes over all of the receptive fields).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66217423",
   "metadata": {},
   "source": [
    "For this first example, we use `{layer : [neurons...]}`, where `neurons` defines a single element from the signal (a slight wrinkle, to keep the indexing consistent between the \"SVD\" basis and the Euclidean basis, is that the index for the signal is `(signal number, x position, y position)`, where x and y are defined by reshaping the signal vector back to the original `channel x height x width dimensions`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2160a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_receptive_fields_weights = {\n",
    "    \"conv1\": [((0, 1, 1)), ((20, 1, 1))],\n",
    "    \"layer1.0.conv2\": [((50,)), ((13, 1, 1))],\n",
    "}\n",
    "\n",
    "\n",
    "_ = dictionary_optimization(model, signals_receptive_fields_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8a6471",
   "metadata": {},
   "source": [
    "For this example, we use `{layer : [(neuron, weight), ...]}`, where `neurons` is the same as above and weight now defines a linear weighting in the optimizaiton. For the example below, for the layer `conv1`, we are weighting the signal `0` at position `x=1, y=1`, i.e. SVD neuron `(0, 1, 1)` by `10`, and we are weighting the SVD neuron `(20, 1, 1)` by `1`. So, the first neuron `(0, 1, 1)` is weighted `10` times the second neuron `(20, 1, 1)`. The same logic holds for the neurons on the layer `layer1.0.conv2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_receptive_fields_weights = {\n",
    "    \"conv1\": [((0, 1, 1), 10), ((20, 1, 1), 1)],\n",
    "    \"layer1.0.conv2\": [((50,), 10), ((13,), 1)],\n",
    "}\n",
    "\n",
    "\n",
    "_ = dictionary_optimization(model, signals_receptive_fields_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e838e",
   "metadata": {},
   "source": [
    "We now consider examples optimizing for an entire channel/SVD signal. For this optimization, we set `neuron=False` in `dictionary_optimization`. Now, we use a single scalar to index the signal. For the example below, we are optimizing for the `0` and `20` signals at layer `conv1`, and for layer `layer1.0.conv2` the `50` and `13` signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0a87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_signals_weights = {\"conv1\": [((0, ), 10), ((20, ), 5)], \"layer1.0.conv2\": [((50,), 10), ((13,), 5)]}\n",
    "layer_signals_weights = {\"conv1\": [0, 20], \"layer1.0.conv2\": [50, 13]}\n",
    "\n",
    "_ = dictionary_optimization(model, layer_signals_weights, neuron=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e94a1",
   "metadata": {},
   "source": [
    "Finally, we can also perform weighted optimization for these signals. We are again passing a dictionary of the form `{layer : [(neuron, weight), ...]}`. Below, for layer `conv1`, we are optimizing neurons `0` and `20` with weights of `0` (i.e. not optimizing for this neuron at all) and `5`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85888977",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_signals_weights = {\"conv1\": [(0, 0), (20, 5)], \"layer1.0.conv2\": [(50, 10), (13, 0)]}\n",
    "\n",
    "_ = dictionary_optimization(model, layer_signals_weights, neuron=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c575109e",
   "metadata": {},
   "source": [
    "### We can do the same for the non-transformed activations (i.e. \"Euclidean\" basis, or just the channel slices or neurons) by setting `neuron_type=NeuronBasis.ACTIVATION`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c4b6cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from deep_data_profiler.optimization import NeuronBasis\n",
    "\n",
    "\n",
    "layer_signals_weights = {\"conv1\": [0, 4]}\n",
    "\n",
    "_ = dictionary_optimization(model, layer_signals_weights, neuron_type=NeuronBasis.ACTIVATION, neuron=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277c02d",
   "metadata": {},
   "source": [
    "Like above, we can also provide weights to the Euclidean basis optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98a757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_data_profiler.optimization import NeuronBasis\n",
    "\n",
    "\n",
    "layer_signals_weights = {\"conv1\": [(0, 1), (20, 5)]}\n",
    "\n",
    "_ = dictionary_optimization(model, layer_signals_weights, neuron_type=NeuronBasis.ACTIVATION, neuron=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
